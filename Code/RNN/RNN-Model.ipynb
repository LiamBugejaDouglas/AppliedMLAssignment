{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f32e7b1",
   "metadata": {},
   "source": [
    "# 1.Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1235d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ba10a",
   "metadata": {},
   "source": [
    "# 2. Import and Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"Dataset/Fake.csv\")\n",
    "df2 = pd.read_csv(\"Dataset/True.csv\")\n",
    "\n",
    "df1['label'] = 1\n",
    "df2['label'] = 0 \n",
    "\n",
    "df1 = df1.drop(columns = ['subject', 'date'])\n",
    "df2 = df2.drop(columns = ['subject', 'date'])\n",
    "\n",
    "df3 = pd.read_csv(\"Dataset/news.csv\")\n",
    "\n",
    "# Use replace to change 'FAKE' to 1 and 'REAL' to 0\n",
    "df3['label'] = df3['label'].replace({'FAKE': 1, 'REAL': 0})\n",
    "df3 = df3.drop(columns = df3.columns[0])\n",
    "\n",
    "df4 = pd.read_csv(\"Dataset/WELFake_Dataset.csv\")\n",
    "\n",
    "df4 = df4.drop(columns = df4.columns[0])\n",
    "df4['label'] = df4['label'].replace({1: 0, 0: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed2700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5bc9e",
   "metadata": {},
   "source": [
    "# 3 Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Rows with empty values\n",
    "print(df.shape[0])\n",
    "df = df.dropna()\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fdc1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplciate data\n",
    "print(df.shape[0])\n",
    "df = df.drop_duplicates(subset=['title'], keep='first')\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7daa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle (randomize) the rows\n",
    "df = df.sample(frac=1, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Title and Text\n",
    "df['final'] = df['title'] + df['text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e467ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing: remove punctuation by character\n",
    "df['final'] = df['final'] .apply(lambda x: x.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))))\n",
    "\n",
    "#Remove Numbers\n",
    "df['final']= df['final'].str.replace(r'\\b\\d+\\b', '', regex=True)\n",
    "\n",
    "# Load English stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "# Apply preprocessing: remove stopwords\n",
    "df['final'] = df['final'].apply(lambda x: ' '.join([word.lower() for word in x.split() if word.lower() not in stopwords_set]))\n",
    "\n",
    "# Apply preprocessing: convert text to lowercase\n",
    "df['final'] = df['final'].apply(lambda x: x.lower())\n",
    "\n",
    "#Reduce words to root form\n",
    "stemmer = PorterStemmer()\n",
    "df['final'] = df['final'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a208c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save DataFrame\n",
    "df.to_pickle('Dataframe_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5607dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the DataFrame back\n",
    "df = pd.read_pickle('../Dataframe_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56afa76",
   "metadata": {},
   "source": [
    "# RNN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d5b3d",
   "metadata": {},
   "source": [
    "### Base RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e7bbd8",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30000  \n",
    "max_length = 150    \n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "# tokenizing the text from our dataset\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(df['final'])\n",
    "sequences = tokenizer.texts_to_sequences(df['final'])\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# splitting data (train and test)\n",
    "labels = df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2dbd7",
   "metadata": {},
   "source": [
    "### Build the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64, input_length=max_length))\n",
    "model.add(SimpleRNN(128))  \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e7da1",
   "metadata": {},
   "source": [
    "### Train the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae33ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9971f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BaseRNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('BaseRNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e9df1",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e1bc1",
   "metadata": {},
   "source": [
    "#### Basic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fce72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a03103",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebb593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(normalized_cm, annot=True, fmt='.2f')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Base RNN Confusion Matrix')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a637a5",
   "metadata": {},
   "source": [
    "#### Receiver Operating Characteristic (ROC) Curve and Area Under Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b705614",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, model.predict(X_test).ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC - Base RNN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721aa73a",
   "metadata": {},
   "source": [
    "### Build the RNN Model - Additional Layers and Dropout Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98ff4d",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30000  \n",
    "max_length = 150    \n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "# tokenizing the text from our dataset\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(df['final'])\n",
    "sequences = tokenizer.texts_to_sequences(df['final'])\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# splitting data (train and test)\n",
    "labels = df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1513a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save sequences (tokens)\n",
    "np.save('padded_sequences.npy', padded)\n",
    "\n",
    "# Save labels\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c4cf2",
   "metadata": {},
   "source": [
    "### Build Adapted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fcbd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64, input_length=max_length))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043dabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8717f60b",
   "metadata": {},
   "source": [
    "### Train Adapted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AddRNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('AddRNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c195c",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e7784c",
   "metadata": {},
   "source": [
    "#### Basic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0f95d",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f1259",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(normalized_cm, annot=True, fmt='.2f')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Adapted RNN Confusion Matrix')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1a1af",
   "metadata": {},
   "source": [
    "#### Receiver Operating Characteristic (ROC) Curve and Area Under Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda988fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, model.predict(X_test).ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC - Adapted RNN')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f1b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
