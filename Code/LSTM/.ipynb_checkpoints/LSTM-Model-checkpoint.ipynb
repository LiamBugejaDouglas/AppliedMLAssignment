{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f32e7b1",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1235d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ba10a",
   "metadata": {},
   "source": [
    "# Import and Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"Dataset/Fake.csv\")\n",
    "df2 = pd.read_csv(\"Dataset/True.csv\")\n",
    "\n",
    "df1['label'] = 1\n",
    "df2['label'] = 0 \n",
    "\n",
    "df1 = df1.drop(columns = ['subject', 'date'])\n",
    "df2 = df2.drop(columns = ['subject', 'date'])\n",
    "\n",
    "df3 = pd.read_csv(\"Dataset/news.csv\")\n",
    "\n",
    "# Use replace to change 'FAKE' to 1 and 'REAL' to 0\n",
    "df3['label'] = df3['label'].replace({'FAKE': 1, 'REAL': 0})\n",
    "df3 = df3.drop(columns = df3.columns[0])\n",
    "\n",
    "df4 = pd.read_csv(\"Dataset/WELFake_Dataset.csv\")\n",
    "\n",
    "df4 = df4.drop(columns = df4.columns[0])\n",
    "df4['label'] = df4['label'].replace({1: 0, 0: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed2700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5bc9e",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Rows with empty values\n",
    "print(df.shape[0])\n",
    "df = df.dropna()\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fdc1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplciate data\n",
    "print(df.shape[0])\n",
    "df = df.drop_duplicates(subset=['title'], keep='first')\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7daa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle (randomize) the rows\n",
    "df = df.sample(frac=1, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Title and Text\n",
    "df['final'] = df['title'] + df['text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e467ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing: remove punctuation by character\n",
    "df['final'] = df['final'] .apply(lambda x: x.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))))\n",
    "\n",
    "#Remove Numbers\n",
    "df['final']= df['final'].str.replace(r'\\b\\d+\\b', '', regex=True)\n",
    "\n",
    "# Load English stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "# Apply preprocessing: remove stopwords\n",
    "df['final'] = df['final'].apply(lambda x: ' '.join([word.lower() for word in x.split() if word.lower() not in stopwords_set]))\n",
    "\n",
    "# Apply preprocessing: convert text to lowercase\n",
    "df['final'] = df['final'].apply(lambda x: x.lower())\n",
    "\n",
    "#Reduce words to root form\n",
    "stemmer = PorterStemmer()\n",
    "df['final'] = df['final'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a208c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save DataFrame\n",
    "df.to_pickle('Dataframe_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the DataFrame back\n",
    "df = pd.read_pickle('../Dataframe_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b645b6ee",
   "metadata": {},
   "source": [
    "# LSTM Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5856ac",
   "metadata": {},
   "source": [
    "## Base LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d6b8a",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define variables \n",
    "vocab_size = 30000  \n",
    "max_length = 150 \n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "# tokenizing the text from our dataset\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(df['final'])\n",
    "sequences = tokenizer.texts_to_sequences(df['final'])\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# splitting data (train and test)\n",
    "labels = df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f0629",
   "metadata": {},
   "source": [
    "### Build Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 16, input_length=max_length))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Optimizer\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e246e7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e768d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147bb095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BaseLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2202b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('BaseLSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2ed0c",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbb4d6",
   "metadata": {},
   "source": [
    "#### Basic Evaluaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5607dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376dd7e",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(normalized_cm, annot=True, fmt='.2f')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Base LSTM Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dd6471",
   "metadata": {},
   "source": [
    "#### Receiver Operating Characteristic (ROC) Curve and Area Under Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41054fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, model.predict(X_test).ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC - Base LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0058b",
   "metadata": {},
   "source": [
    "## LSTM - Additional Layer and Dropout Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e85d8a",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Variables\n",
    "vocab_size = 30000  \n",
    "max_length = 150 \n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "# tokenizing the text from our dataset\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(df['final'])\n",
    "sequences = tokenizer.texts_to_sequences(df['final'])\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# splitting data (train and test)\n",
    "labels = df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df287224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save sequences (tokens)\n",
    "np.save('padded_sequences.npy', padded)\n",
    "\n",
    "# Save labels\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f14859",
   "metadata": {},
   "source": [
    "### Build Adapted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Embedding(vocab_size, 16, input_length=max_length))\n",
    "model_1.add(LSTM(32, return_sequences=True))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(LSTM(32))\n",
    "model_1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43cea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Optimizer\n",
    "model_1.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2389521",
   "metadata": {},
   "source": [
    "### Train Adapted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "model_1.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fdab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('AddLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4003dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = load_model('AddLSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c14c8b",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9954dac",
   "metadata": {},
   "source": [
    "#### Basic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2cd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = model_1.predict(X_test)\n",
    "predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f96f6",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d27d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(normalized_cm, annot=True, fmt='.2f')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Adapted LSTM Confusion Matrix')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4ec8b",
   "metadata": {},
   "source": [
    "#### Receiver Operating Characteristic (ROC) Curve and Area Under Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, model_1.predict(X_test).ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC - Adapted LSTM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
